# Daily Learning Log

### Day 1
 - Revised python Fundamental
 - OOP


### Day 2 – NumPy
- Learned NumPy arrays, creation methods, indexing, slicing, reshaping, broadcasting, and vectorization  
- Compared NumPy vs Python lists for performance, memory usage, and data operations

### Day 3 – Pandas Indexing & Filtering

- Learned data selection using loc, iloc, at, iat, column selection, and slicing rules

- Practiced boolean filtering and SQL-like querying using df.query()

### Day 4 – Pandas Data Cleaning & Transformation

- Learned handling missing values, duplicates, data type conversion, and string operations

- Practiced data transformation, sorting, renaming, reordering columns, and index management

### Day 5 – API Data Collection & Web Scraping

- Learned how to fetch data from public APIs using requests and convert JSON responses into Pandas DataFrames

- Practiced web scraping using requests + BeautifulSoup to extract, clean, and store structured data into CSV files

### Day 6 – Pagination Scraping & Data Extraction

- Learned how to scrape multiple web pages using pagination and automatically stop when no more pages are found

- Practiced extracting specific content (quotes, authors, tags), filtering data based on conditions, and storing results in Pandas DataFrames


### Day 7 – Data Visualization with Matplotlib

- Practiced basic plotting using NumPy and Matplotlib

- Created histograms with custom bins and multiple datasets

- Visualized data using box plots and stack plots

- Learned to add labels, legends, grids, and reference lines

### Day 8 – Advanced Matplotlib & Plot Styling

- Built subplots using both procedural and OOP Matplotlib approaches

- Compared datasets using line plots, bar charts, scatter plots, and pie charts

- Applied plot styling, themes, annotations, and color maps

- Saved figures and improved layout using tight_layout()



### Day 9 - Introduction to Seaborn & Relational Plots

- Explored the Seaborn library for statistical data visualization

- Loaded built-in datasets like tips and flights

- Created relational plots with sns.relplot:

- Scatter plots with multiple dimensions (hue, size, style)

- Line plots to show trends over variables

- Practiced line plots using both Seaborn and Matplotlib

- Learned to add markers, legends, and customize axes


### Day 10 – Advanced Seaborn & Matplotlib Visualizations

- Visualized distributions with sns.histplot and overlayed mean lines

- Explored categorical plots:

- Bar plots (sns.barplot)

- Box plots (sns.boxplot) with hue separation

- Worked with matrix-style plots:

- Pivoted flights data to create heatmaps (sns.heatmap)

- Annotated heatmaps with values and customized color maps

- Applied best practices in Matplotlib:

- Titles, axis labels, grids, legends, tight layout adjustments

- Combined Seaborn plots with Matplotlib axes for greater control

- Built composite figures:

- Multiple subplots using plt.subplots()

- Histograms with KDE, vertical lines for mean, customized axes

- Analyzed real-life datasets visually:

- penguins dataset: scatter plots of flipper_length_mm vs body_mass_g

- tips dataset: pivot tables and heatmaps for average tip by day and time


### Day 11,12,13,14,15 - Probability

- Complementary, Addition, Multiplication Rule
- Conditional, Law of Total Probability
- Bayes Theorem, Random Variables
- Probability Distribution - Binomial, Uniform, Normal
- Central Limit Theorem
- Do lot of practice

### Day 16-23  Math For AI -> Linear Algebra

- Straight Lines, Distance between 2 point, Parallel, Perpendicular lines, Distance between Parallel Lines
- Vectors, Addition, Sub, Mult, Dot and Cross Product
- Matrix, Operations on Matrices, Eigen Vectors and Eigen Values

### Day 24 - 30 Math for AI -> Calculus

- Function, Composite Function
- Functions: Scaler Multiplication and Addition
- Input:  Scaler Multiplication and Addition
- Diffrentiations -> Rules, Find Minima maxima

### Day 31  SuperVised Learning - Linear Regression

- Best fit Line
- Cost Function
- Gradient Descent
- Cost Function Curve
- Insurence Prediction Using Linear Regression


### Day 32 - Encoding, Feature Engineering

- Categorical and one hot encodin
- Multicolinearity, Dummy Variable trap
- Other Feature Engineering like - Iteractions



### Day 33 - Regularization Implement with Intuition

- Underfit, overfit, Bias, Variance
- Lasso, Ridge Regration
- Using LassoCV, ElasticNet 


### day 34 - Logistic Regression

- Logistic Regression Algorithm Intuition
- Implementation using a dataset
- Cost function

### Day 35 - Normalization and Evaluation Metrics

- Standardization and Normalization
- Confusion Matrix, Classification Metrics
- Evaluate with Metrics

### Day 36 - Naive Bayes and KNN

- Algorithm, Implementation, Types of Naive bayes


### Day 37 - Cross Validation
- CV for HyperParameter tuning
- Pipeline in Sklearn

### Day 38 - Practice on Iris Dataset

- Apply all this things for classify what I learn
- House Prediction Aplly KNN, LR, Naive

### Day 39 - Scratch Implementation
 - Linear Regression, LR with OLS
 - Logistic Regression
 - KNN Classifier, KNN Regression

### Day 40 - Minor Project

- Credit Wise Loan System
- Handle Missing data, EDA, Encoding
- Feature Scaling, Feature Engineering

### Day 41 - Decision Tree (Classifier)
- DT Classifier
- Entropy, Gini Impurity, Information gain 
- Pruning Decision Trees
- Pruning Rules

### Day 42 - Decision Tree (Regression)
- Pre - Pruning, Post pruning
-  Variance Reduction
- Do a small Project Applying Decision Tree Algorithm

### Day 43 - SVM (CLassifier)

- SVM Intuition, Mathmatical logic
- Classification Hyperparameters
- kernel in SVM
- Kernels Types

### Day 44 - SVM (Regression)
- SVM Regressor Intuition
- GridSearchCV for HyperParameter
- LinearSVR vs SVR

### Day 45 - Ensemble Learning (Random Forest)
- Bagging, Boosting
- Random Forest
- Out of Bag
- Decision Tree vs Random Forest

### Day 46 - Bagging Classifier and Regressor
- Random Forest Regressor
- Intuition and Implementation

### Day 47 - Gradient Boosting

- Gradient Boosting Regressor
- Gradient Boosting classifier
- AdaBoost

### Day 48 - XGBoost
- Other Boosting, LightGB,
- Homogenous vs Heterogenous Ensemble
- Voting

### Day 49 - Stacking

- Blending
- Novagens Labs Project -> Health Prediction

### Day 50 - Unsupervised ML

- Clustering
- K-Means Clustering
- Elbow Method for K

### Day 51 - Practical Implementation of K-Means
- Silhouette Score for K
- Random Initialization Trap
- K-Means on Iris Dataset

### Day 52 -  Hierarchical Cluster
- Agglomerative and Divisive Clustering
- Dendrogram
- KMeans Vs Hierarchical

### Day 53 - DBSCAN Clustering
- Core Point, Boundary point, Outlier
- Hypertuning
- Kmeans vs DBSCAN in Non-linear data

### Day 54 - Dimensionality Reduction
- Curse of Dimensionality
- Solving Different way
- Outlier, Noise, Anomaly
- Primary Component Analysis

### Day 55 -  Anomaly Detection
- DBSCAN for Anomalies
- Isolation Forest for Anomalies
- Local outlier factor - LOF

### Day 56 - Project SmartCart Clustering System
- Handle missing data, Feature Engineering
- Handle Outliers, Drop Columns, Feature encoding ans Scaling
- Visualization, Choose k (Elbow and Silhouette score)
- Segementation using k-Means, Agglomerative Clustering
- Characterization and Summary Profilling 

### Day 57 - Perticipate Kaggle competition Predicting Heart Disease

- [Competion Link](https://www.kaggle.com/competitions/playground-series-s6e2)
- Accuracy got 95%

### Day 58 - Deep Learning (Perceptron)

- ML vs DL
- ANN, In depth Perceptron
- Building a Neuron

### Day 59 - Forward and Backward Propagation

- Loss Functions (Regression + Classification) - Mathematical Intuition
- Weight and Bias Updation
- Chain Rule of Derivatives in NN

### Day 60 - Vanishing Gradient Problem

- RELU and its Vairaints
- BATCH vs Iteration vs Epoch
- Optimizers
- Modern Variants of GD